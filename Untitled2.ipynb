{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a83d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first phase: constraint identification, identify constraints with a chi squared test or some traditional methods\n",
    "#fix my algorithm, identify obligatory parents, identify other form of constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52677ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a graph of time vs significance level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705a48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed up, find the balance between parent limit, iteration of the whole loop (+ or - on different network sizes)\n",
    "#use PC algorithm from a different source and compare it with your results.\n",
    "#PROBLEM: when running gobnilp, and setting parent limit to unlimited, it runs too slowly, how do i make it faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Once the skeletal structure of the graph has been obtained, we move on to the second phase, where we identify \\textbf{v-structures}.\n",
    "\n",
    "\\begin{definition}\n",
    "    (\\textbf{v-structure} A v-structure is a structure within the graph which takes the following form $A -> B <- C$)\n",
    "\\end{definition}\n",
    "\n",
    "\\begin{enumerate}\n",
    "    \\setcounter{enumi}{1}\n",
    "    \\item Find every triple of vertices in the graph with variables A, B, C such that $(A - C - B)$, check if $ C \\in S_{ab}$. If so, move onto the next step. Else orient the edges such that $(A -> C <- B)$\n",
    "\\end{enumerate}\n",
    "\n",
    "As we have identified in our CI test that C is indeed an element in the set $S_{ab}$ which d-separates A and B, implying A and B are independent when C is observed $ (A \\perp B \\mid C)$. Once every v-structure in the graph has been identified, we move onto the final step, that is to prevent cycles being formed or more v-structures from being created.\n",
    "\n",
    "\\begin{enumerate}\n",
    "\\setcounter{enumi}{2}\n",
    "    \\item In the partially directed graph, orient as many edges as possible while making sure no new v-structures are created and no directed cycles are formed.\n",
    "\\end{enumerate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6753a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "0. how does a hybrid approach to learning bayesian network work? (in which order are the tests applied)\n",
    "1. when adding itertools.combinations(n,2) to medium sized network, it takes a very long time to run\n",
    "2. considering parent limit as a constraint, how to test?\n",
    "3. considering obligatory nodes as a constraint.\n",
    "4. in the report, should i include stuff such as accuracy of the hypothesis tests? (type I error and type II error)\n",
    "5. comparison of adding constraints on different networks of different sizes\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0fe5c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nassumption 1: two variables measured on a continuous scale\\nassumption 2: each variables must be paired\\nassumption 3: each \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pearson's product moment correlation coefficient\n",
    "'''\n",
    "Probabilistic reasoning:\n",
    "conditionally independent - page 104 \n",
    "chow liu - page 408\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a Bayesian network, the joint probability distribution of the network is given by\n",
    "\\begin{math}\n",
    "    P(x_1,x_2,...,x_n) \n",
    "\\end{math}, by the chain rule, we then simplify this to  $$\\begin{math}\n",
    "P(x_1, x_2, ... , x_n) = P(x_n | x_{n-1}, x_{n-2}, ... , x_1) P(x_{n-1} | x_{n-2}, x_{n-3}, ... , x_1) ... P(x_2 | x_1) P(x_1)\n",
    "\\end{math}   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "References:\n",
    "Abstract:\n",
    "[1] : https://ermongroup.github.io/cs228-notes/learning/structure/#:~:text=The%20score%2Dbased%20approach%20first,structure%20achieving%20the%20maximal%20score.\n",
    "[2] : Cooper, G.F., Herskovits, E. A Bayesian method for the \n",
    "induction of probabilistic networks from data. Mach Learn 9, 309–347 (1992). \n",
    "https://doi.org/10.1007/BF00994110\n",
    "\n",
    "Background:\n",
    "remember to talk about conditional probabilities, posterior, likelihood etc.\n",
    "[3] https://www.uib.no/en/rg/ml/119695/bayesian-networks\n",
    "[4] https://www.cs.helsinki.fi/u/bmmalone/presentations/ijcai2013_StructureLearningComplete.pdf\n",
    "[6] Eugene Charniak. 1991. Bayesian networks without tears: making Bayesian networks more accessible to the probabilistically unsophisticated. AI Mag. 12, 4 (Winter 1991), 50–63.\n",
    "[7] https://arxiv.org/abs/1212.2468 Learning bayesian networks is NP-Hard\n",
    "[8] http://proceedings.mlr.press/v138/sharma20a/sharma20a.pdf definition of score based search\n",
    "[9] https://www.cs.york.ac.uk/aig/sw/gobnilp/ Gobnilp\n",
    "[10] https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=dd40e08c98b2e77894e91489b51e46bd6fb9bc44 IP gobnilp\n",
    "\n",
    "Related works (lit review):\n",
    "[11] Pearl and Vemma inductive causation (1990)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44903c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Abstract:\n",
    "(insert abstract here)\n",
    "\n",
    "Introduction:\n",
    "-Define a bayesian network (include diagrams)\n",
    "-define a score based algorithm (gobnilp, optimization problem, IP)\n",
    "-define a constraint-based algorithm\n",
    "-define a hybrid algorithm\n",
    "-define the problem and how you are going to solve it.\n",
    "-even if the network is the true bayesian network, it might get scored lower than the most optimal bayesian network given by the scoring function\n",
    "-definitions\n",
    "\n",
    "Literature review:\n",
    "-because this is an NP-hard problem, so what have the community done to find the most optimal bayesian network\n",
    "-examples of score-based algorithms\n",
    "-example of constraint based algorithms\n",
    "-examples of hybrid algorithms\n",
    "-other learning approaches (bayesian model averaging, )\n",
    "-how is this done differently?\n",
    "-\n",
    "Methods: (in no particular order)\n",
    "3.1 Chi2 test (problems with using chi2 test on smaller networks vs larger networks)\n",
    "3.12 sig level\n",
    "3.13 PC algorthm\n",
    "3.15 skeletal structure learning\n",
    "3.16 gobnilp (score-based algorithm, )\n",
    "3.2 errors of the hypothesis test (type I and type II errors and the sources of these error (p-value))\n",
    "3.3 data used (alarm network, asia network, etc)\n",
    "3.4 d-separation\n",
    "3.45 PC (part 1) algorithm\n",
    "Results:\n",
    "\n",
    "3.5 results with different size networks\n",
    "3.6 results with different palim\n",
    "etc\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6e539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: FIND MY CONSTRAINTS\n",
    "#TODO: BAYES FACTOR? http://www.ai.lab.uec.ac.jp/wp-content/uploads/2018/08/Constraint-based-learning-Bayesian-networks-using-Bayes-factor.pdf\n",
    "#TODO: RAI ALGORITHM https://www.jmlr.org/papers/volume10/yehezkel09a/yehezkel09a.pdf\n",
    "#TODO: VERY GOOD BOOK : https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1174&context=open_access_dissertations\n",
    "#TODO: minimal-d-separation: https://ftp.cs.ucla.edu/pub/stat_ser/r254.pdf\n",
    "#TODO: pearl: probabilistic reasoning in intelligent systems: https://dl.acm.org/doi/10.5555/534975\n",
    "#TODO: test PC algorithm on each dataset and find the time taken for computing first order CI\n",
    "#TODO: constraint 2 https://www.biostat.wisc.edu/~page/SC.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befa65c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, ('A', 'B'), False], [1, ('A', 'C'), True], [2, ('A', 'D'), False], [3, ('A', 'E'), False], [4, ('A', 'F'), True], [5, ('B', 'C'), True], [6, ('B', 'D'), False], [7, ('B', 'E'), False], [8, ('B', 'F'), True], [9, ('C', 'D'), False], [10, ('C', 'E'), True], [11, ('C', 'F'), True], [12, ('D', 'E'), False], [13, ('D', 'F'), True], [14, ('E', 'F'), False]]\n"
     ]
    }
   ],
   "source": [
    "from pygobnilp.gobnilp import Gobnilp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.estimators.CITests import chi_square\n",
    "from pgmpy.estimators import PC\n",
    "from conditional import *\n",
    "from gurobipy import *\n",
    "import random\n",
    "import re\n",
    "import keyword"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
